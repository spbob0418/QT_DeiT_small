{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.7406, 0.0414, 0.5075, 0.0692, 0.8851],\n",
      "        [0.1557, 0.5919, 0.0637, 0.9499, 0.7746],\n",
      "        [0.0336, 0.8756, 0.5281, 0.3327, 0.2997]])\n",
      "tensor([[0.7406, 0.8756, 0.5281, 0.9499, 0.8851]])\n",
      "q_x tensor([[7., 0., 7., 1., 7.],\n",
      "        [1., 5., 1., 7., 6.],\n",
      "        [0., 7., 7., 2., 2.]])\n",
      "s_x tensor([[0.1058, 0.1251, 0.0754, 0.1357, 0.1264]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def round_pass(x):\n",
    "    y = x.round()\n",
    "    y_grad = x\n",
    "    return y.detach() - y_grad.detach() + y_grad\n",
    "\n",
    "class Quantizer():\n",
    "    def __init__(self, N_bits: int, type: str = \"per_tensor\",  signed: bool = True, symmetric: bool = True):\n",
    "        super().__init__()\n",
    "            \n",
    "        self.N_bits = N_bits\n",
    "        self.signed = signed\n",
    "        self.symmetric = symmetric\n",
    "        self.q_type = type\n",
    "        # self.eps = torch.iinfo(dtype).eps\n",
    "        # self.minimum_range = torch.iinfo(dtype).eps\n",
    "        if self.N_bits is None:\n",
    "            return \n",
    "\n",
    "        if self.signed:\n",
    "            self.Qn = - 2 ** (self.N_bits - 1)\n",
    "            self.Qp = 2 ** (self.N_bits - 1) - 1\n",
    "        else:\n",
    "            self.Qn = 0\n",
    "            self.Qp = 2 ** self.N_bits - 1\n",
    "\n",
    "    def __call__(self, x):  \n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, x): \n",
    "        if self.N_bits is None:\n",
    "            return x, 1\n",
    "\n",
    "        if self.symmetric:\n",
    "            if self.q_type == 'per_tensor': \n",
    "                max_x = x.abs().max().detach()\n",
    "            elif self.q_type == 'per_token': \n",
    "                max_x = x.abs().amax(dim=-1, keepdim=True).detach()\n",
    "            elif self.q_type == 'per_channel': \n",
    "                max_x = x.abs().amax(dim=0, keepdim=True).detach()\n",
    "\n",
    "            print(max_x)\n",
    "            scale = max_x / self.Qp\n",
    "            x = x / scale \n",
    "            x = round_pass(x.clamp_(self.Qn, self.Qp)) \n",
    "            \n",
    "        else: #Asymmetric\n",
    "            min_x = x.min().detach()\n",
    "            max_x = x.max().detach()\n",
    "            range_x = (max_x - min_x).detach().clamp_(min=self.minimum_range)\n",
    "            scale = range_x / (self.Qp - self.Qn)\n",
    "\n",
    "            zero_point = torch.round((min_x / scale) - self.Qn)\n",
    "\n",
    "            x = (x / scale) + zero_point\n",
    "            x = round_pass(x.clamp_(self.Qn, self.Qp))\n",
    "\n",
    "        return x, scale\n",
    "\n",
    "quantizer = Quantizer (4, 'per_channel')\n",
    "\n",
    "x = torch.rand(3,5) \n",
    "print(\"x\",x)\n",
    "\n",
    "q_x, s_x = quantizer(x)\n",
    "print(\"q_x\", q_x)\n",
    "print(\"s_x\", s_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.4.1-cp38-cp38-manylinux1_x86_64.whl (797.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 797.1 MB 28 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.7 MB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.1 MB 10.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 56.5 MB 10.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 121.6 MB 12.3 MB/s eta 0:00:01    |███████████████████████▊        | 90.0 MB 10.6 MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 196.0 MB 10.5 MB/s eta 0:00:01     |█████████████████████▌          | 131.3 MB 12.0 MB/s eta 0:00:06\n",
      "\u001b[?25hCollecting triton==3.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\"\n",
      "  Downloading triton-3.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 209.4 MB 125 kB/s  eta 0:00:01██████▋       | 160.8 MB 810 kB/s eta 0:01:00\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 124.2 MB 12.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /home/shkim/.local/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Collecting nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 176.2 MB 285 kB/s  eta 0:00:01    |██▊                             | 15.2 MB 12.3 MB/s eta 0:00:14██████████▉                     | 59.5 MB 11.9 MB/s eta 0:00:10\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 410.6 MB 19 kB/s s eta 0:00:01     |█████████████████████           | 269.0 MB 10.6 MB/s eta 0:00:14     |███████████████████████████████▏| 399.7 MB 12.3 MB/s eta 0:00:01     |███████████████████████████████▋| 405.9 MB 12.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "\u001b[K     |████████████████████████████████| 179 kB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[K     |████████████████████████████████| 823 kB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.2 MB 11.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 9.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 664.8 MB 20 kB/s s eta 0:00:01     |█████▋                          | 117.6 MB 10.9 MB/s eta 0:00:51�█████████▍                 | 298.0 MB 10.8 MB/s eta 0:00:34�█████████▊                 | 306.4 MB 12.3 MB/s eta 0:00:30�█▉                 | 307.5 MB 12.3 MB/s eta 0:00:29��█▎            | 400.7 MB 11.0 MB/s eta 0:00:25     |█████████████████████████▍      | 528.0 MB 11.0 MB/s eta 0:00:13     |███████████████████████████▌    | 570.2 MB 10.3 MB/s eta 0:00:10\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (2.10.1)\n",
      "Collecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.7 MB 12.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[K     |████████████████████████████████| 536 kB 11.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, filelock, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-nvjitlink-cu12, nvidia-cusparse-cu12, triton, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-nccl-cu12, networkx, fsspec, nvidia-cuda-runtime-cu12, mpmath, sympy, nvidia-nvtx-cu12, nvidia-cudnn-cu12, torch\n",
      "Successfully installed filelock-3.16.1 fsspec-2024.10.0 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 sympy-1.13.3 torch-2.4.1 triton-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
