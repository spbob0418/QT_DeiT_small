{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.5318, 0.7585, 0.7211, 0.5480, 0.9295],\n",
      "        [0.0402, 0.1398, 0.4303, 0.4139, 0.3432],\n",
      "        [0.3358, 0.5768, 0.3559, 0.3142, 0.0769]])\n",
      "tensor([[0.5318, 0.7585, 0.7211, 0.5480, 0.9295]])\n",
      "q_x tensor([[7., 7., 7., 7., 7.],\n",
      "        [1., 1., 4., 5., 3.],\n",
      "        [4., 5., 3., 4., 1.]])\n",
      "s_x tensor([[0.0760, 0.1084, 0.1030, 0.0783, 0.1328]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def round_pass(x):\n",
    "    y = x.round()\n",
    "    y_grad = x\n",
    "    return y.detach() - y_grad.detach() + y_grad\n",
    "\n",
    "class Quantizer():\n",
    "    def __init__(self, N_bits: int, type: str = \"per_tensor\",  signed: bool = True, symmetric: bool = True):\n",
    "        super().__init__()\n",
    "            \n",
    "        self.N_bits = N_bits\n",
    "        self.signed = signed\n",
    "        self.symmetric = symmetric\n",
    "        self.q_type = type\n",
    "        # self.eps = torch.iinfo(dtype).eps\n",
    "        # self.minimum_range = torch.iinfo(dtype).eps\n",
    "        if self.N_bits is None:\n",
    "            return \n",
    "\n",
    "        if self.signed:\n",
    "            self.Qn = - 2 ** (self.N_bits - 1)\n",
    "            self.Qp = 2 ** (self.N_bits - 1) - 1\n",
    "        else:\n",
    "            self.Qn = 0\n",
    "            self.Qp = 2 ** self.N_bits - 1\n",
    "\n",
    "    def __call__(self, x):  \n",
    "        return self.forward(x)\n",
    "\n",
    "    def forward(self, x): \n",
    "        if self.N_bits is None:\n",
    "            return x, 1\n",
    "\n",
    "        if self.symmetric:\n",
    "            if self.q_type == 'per_tensor': \n",
    "                max_x = x.abs().max().detach()\n",
    "            elif self.q_type == 'per_token': \n",
    "                max_x = x.abs().amax(dim=-1, keepdim=True).detach()\n",
    "            elif self.q_type == 'per_channel': \n",
    "                max_x = x.abs().amax(dim=0, keepdim=True).detach()\n",
    "\n",
    "            print(max_x)\n",
    "            scale = max_x / self.Qp\n",
    "            x = x / scale \n",
    "            x = round_pass(x.clamp_(self.Qn, self.Qp)) \n",
    "            \n",
    "        else: #Asymmetric\n",
    "            min_x = x.min().detach()\n",
    "            max_x = x.max().detach()\n",
    "            range_x = (max_x - min_x).detach().clamp_(min=self.minimum_range)\n",
    "            scale = range_x / (self.Qp - self.Qn)\n",
    "\n",
    "            zero_point = torch.round((min_x / scale) - self.Qn)\n",
    "\n",
    "            x = (x / scale) + zero_point\n",
    "            x = round_pass(x.clamp_(self.Qn, self.Qp))\n",
    "\n",
    "        return x, scale\n",
    "\n",
    "quantizer = Quantizer (4, 'per_channel')\n",
    "\n",
    "x = torch.rand(3,5) \n",
    "print(\"x\",x)\n",
    "\n",
    "q_x, s_x = quantizer(x)\n",
    "print(\"q_x\", q_x)\n",
    "print(\"s_x\", s_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top3_indices_flat [1 5 2]\n",
      "channel_dim 3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def process_tensor(x,iteration, layer: str):\n",
    "    # x: Tensor of shape [BS, sequence_length, channel_dim]\n",
    "    BS = x.shape[0]\n",
    "    sequence_length = x.shape[1]\n",
    "    channel_dim = x.shape[2]\n",
    "    num_elements = sequence_length * channel_dim\n",
    "\n",
    "    top1_values = []\n",
    "    top3_values = []\n",
    "    top3_indices = []\n",
    "    top1_percent_values = []\n",
    "    median_values = []\n",
    "\n",
    "    for i in range(BS):\n",
    "        sample = x[i]  # Shape [sequence_length, channel_dim]\n",
    "        flattened = sample.view(-1)  # Flatten to 1D tensor of size sequence_length * channel_dim\n",
    "        sorted_values, sorted_indices = torch.sort(flattened, descending=True)\n",
    "\n",
    "        # Top1\n",
    "        top1_value = sorted_values[0].item()\n",
    "        top1_values.append(top1_value)\n",
    "\n",
    "\n",
    "        # Top3\n",
    "        top3_values_i = sorted_values[:3].cpu().numpy()\n",
    "        top3_indices_flat = sorted_indices[:3].cpu().numpy()\n",
    "        # Map back to 2D indices\n",
    "        print(\"top3_indices_flat\",top3_indices_flat )\n",
    "        print(\"channel_dim\",channel_dim )\n",
    "\n",
    "        \n",
    "        top3_rows = top3_indices_flat // channel_dim\n",
    "        top3_cols = top3_indices_flat % channel_dim\n",
    "        top3_indices_i = list(zip(top3_rows, top3_cols))\n",
    "        top3_values.append(top3_values_i)\n",
    "        top3_indices.append(top3_indices_i)\n",
    "\n",
    "        # Top1% elements\n",
    "        top1_percent_count = max(1, int(np.ceil(num_elements * 0.01)))\n",
    "        top1_percent = sorted_values[:top1_percent_count].cpu().numpy()\n",
    "        top1_percent_values.append(top1_percent)\n",
    "\n",
    "        # Median value\n",
    "        median = torch.median(flattened).item()\n",
    "        median_values.append(median)\n",
    "\n",
    "    # Compute mean and standard deviation for each quantity\n",
    "    top1_mean = np.mean(top1_values)\n",
    "    top1_std = np.std(top1_values)\n",
    "\n",
    "    top3_means = [np.mean(vals) for vals in top3_values]\n",
    "    top3_mean = np.mean(top3_means)\n",
    "    top3_std = np.std(top3_means)\n",
    "\n",
    "    top1_percent_mean = np.mean([np.mean(vals) for vals in top1_percent_values])\n",
    "    top1_percent_std = np.std([np.mean(vals) for vals in top1_percent_values])\n",
    "\n",
    "    median_mean = np.mean(median_values)\n",
    "    median_std = np.std(median_values)\n",
    "    epoch = iteration//1252\n",
    "    # Save results to a file\n",
    "    with open('probe_result.txt', 'a') as f:\n",
    "        f.write('Epoch: {}\\n'.format(epoch))\n",
    "        f.write('Layer info: {}\\n'.format(layer))\n",
    "\n",
    "        f.write('Top1 Mean: {:.4f}, Top1 Std: {:.4f}\\n'.format(top1_mean, top1_std))\n",
    "        f.write('Top3 Mean: {:.4f}, Top3 Std: {:.4f}\\n'.format(top3_mean, top3_std))\n",
    "        f.write('Top1% Mean: {:.4f}, Top1% Std: {:.4f}\\n'.format(top1_percent_mean, top1_percent_std))\n",
    "        f.write('Median Mean: {:.4f}, Median Std: {:.4f}\\n'.format(median_mean, median_std))\n",
    "\n",
    "        f.write('\\nTop 3 values and their positions for each sample:\\n')\n",
    "        for i in range(BS):\n",
    "            f.write('Sample {}:\\n'.format(i))\n",
    "            for rank, (value, (row, col)) in enumerate(zip(top3_values[i], top3_indices[i]), 1):\n",
    "                f.write('  Rank {}: Value {:.4f} at position (sequence index {}, channel index {})\\n'.format(\n",
    "                    rank, value, row, col))\n",
    "        f.write('\\n' + '-' * 50 + '\\n')  # Separator between calls\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x = torch.rand(256,197,384)\n",
    "x = torch.tensor([[[1, 10, 5], \n",
    "     [4, 5, 7]]])\n",
    "process_tensor(x, 15, 'dd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top3_indices_flat [1 5 2]\n",
      "channel_dim 3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "\n",
    "def process_tensor(x,iteration, layer: str):\n",
    "    # x: Tensor of shape [BS, sequence_length, channel_dim]\n",
    "    BS = x.shape[0]\n",
    "    sequence_length = x.shape[1]\n",
    "    channel_dim = x.shape[2]\n",
    "    num_elements = sequence_length * channel_dim\n",
    "\n",
    "    top1_values = []\n",
    "    top3_values = []\n",
    "    top3_indices = []\n",
    "    top1_percent_values = []\n",
    "    median_values = []\n",
    "\n",
    "    for i in range(BS):\n",
    "        sample = x[i]  # Shape [sequence_length, channel_dim]\n",
    "        flattened = sample.view(-1)  # Flatten to 1D tensor of size sequence_length * channel_dim\n",
    "        sorted_values, sorted_indices = torch.sort(flattened, descending=True)\n",
    "\n",
    "        # Top1\n",
    "        top1_value = sorted_values[0].item()\n",
    "        top1_values.append(top1_value)\n",
    "\n",
    "\n",
    "        # Top3\n",
    "        top3_values_i = sorted_values[:3].cpu().numpy()\n",
    "        top3_indices_flat = sorted_indices[:3].cpu().numpy()\n",
    "        # Map back to 2D indices\n",
    "        print(\"top3_indices_flat\",top3_indices_flat )\n",
    "        print(\"channel_dim\",channel_dim )\n",
    "\n",
    "        \n",
    "        top3_rows = top3_indices_flat // channel_dim\n",
    "        top3_cols = top3_indices_flat % channel_dim\n",
    "        top3_indices_i = list(zip(top3_rows, top3_cols))\n",
    "        top3_values.append(top3_values_i)\n",
    "        top3_indices.append(top3_indices_i)\n",
    "\n",
    "        # Top1% elements\n",
    "        top1_percent_count = max(1, int(np.ceil(num_elements * 0.01)))\n",
    "        top1_percent = sorted_values[:top1_percent_count].cpu().numpy()\n",
    "        top1_percent_values.append(top1_percent)\n",
    "\n",
    "        # Median value\n",
    "        median = torch.median(flattened).item()\n",
    "        median_values.append(median)\n",
    "\n",
    "    # Compute mean and standard deviation for each quantity\n",
    "    top1_mean = np.mean(top1_values)\n",
    "    top1_std = np.std(top1_values)\n",
    "\n",
    "    top3_means = [np.mean(vals) for vals in top3_values]\n",
    "    top3_mean = np.mean(top3_means)\n",
    "    top3_std = np.std(top3_means)\n",
    "\n",
    "    top1_percent_mean = np.mean([np.mean(vals) for vals in top1_percent_values])\n",
    "    top1_percent_std = np.std([np.mean(vals) for vals in top1_percent_values])\n",
    "\n",
    "    median_mean = np.mean(median_values)\n",
    "    median_std = np.std(median_values)\n",
    "    epoch = iteration//1252\n",
    "\n",
    "    # 통계 데이터를 probe_result.csv에 기록\n",
    "    with open('/home/shkim/QT_DeiT_small/probe_result.csv', 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if f.tell() == 0:  # 파일이 비어 있으면 헤더 추가\n",
    "            writer.writerow(['Epoch', 'Layer', 'Top1 Mean', 'Top1 Std', 'Top3 Mean', 'Top3 Std', \n",
    "                             'Top1% Mean', 'Top1% Std', 'Median Mean', 'Median Std'])\n",
    "        writer.writerow([epoch, layer, top1_mean, top1_std, top3_mean, top3_std, \n",
    "                         top1_percent_mean, top1_percent_std, median_mean, median_std])\n",
    "\n",
    "    # 각 배치의 Top3 인덱스를 top3_indices.csv에 기록\n",
    "    with open('/home/shkim/QT_DeiT_small/top3_indices.csv', 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if f.tell() == 0:  # 파일이 비어 있으면 헤더 추가\n",
    "            writer.writerow(['Epoch', 'Layer', 'Sample Index', 'Rank', 'Row Index', 'Channel Index'])\n",
    "        \n",
    "        for i, indices in enumerate(top3_indices):\n",
    "            for rank, (row, col) in enumerate(indices, 1):\n",
    "                writer.writerow([epoch, layer, i, rank, row, col])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x = torch.rand(256,197,384)\n",
    "x = torch.tensor([[[1, 10, 5], \n",
    "     [4, 5, 7]]])\n",
    "process_tensor(x, 15, 'dd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 12.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tzdata>=2022.1\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[K     |████████████████████████████████| 346 kB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /home/shkim/.local/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /home/shkim/.local/lib/python3.8/site-packages (from pandas) (1.24.4)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "\u001b[K     |████████████████████████████████| 508 kB 10.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.14.0)\n",
      "Installing collected packages: tzdata, pytz, pandas\n",
      "Successfully installed pandas-2.0.3 pytz-2024.2 tzdata-2024.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           10.0\n",
      "1           10.0\n",
      "2           10.0\n",
      "3           10.0\n",
      "4     ----------\n",
      "5      Top1 Mean\n",
      "6           10.0\n",
      "7           10.0\n",
      "8           10.0\n",
      "9           10.0\n",
      "10    ----------\n",
      "Name: Top1 Mean, dtype: object\n",
      "     Top1 Mean          Top3 Mean\n",
      "0         10.0  7.333333333333333\n",
      "1         10.0  7.333333333333333\n",
      "2         10.0  7.333333333333333\n",
      "3         10.0  7.333333333333333\n",
      "4   ----------         ----------\n",
      "5    Top1 Mean          Top3 Mean\n",
      "6         10.0  7.333333333333333\n",
      "7         10.0  7.333333333333333\n",
      "8         10.0  7.333333333333333\n",
      "9         10.0  7.333333333333333\n",
      "10  ----------         ----------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 경로\n",
    "file_path = '/home/shkim/QT_DeiT_small/probe_result.csv'\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 특정 열 추출 (예: 'Top1 Mean' 열을 추출하는 경우)\n",
    "top1_mean_column = df['Top1 Mean']\n",
    "\n",
    "# 여러 열 추출 (예: 'Top1 Mean'과 'Top3 Mean' 열을 동시에 추출하는 경우)\n",
    "selected_columns = df[['Top1 Mean', 'Top3 Mean']]\n",
    "\n",
    "# 출력 확인\n",
    "print(top1_mean_column)\n",
    "print(selected_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
